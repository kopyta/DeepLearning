{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iPr8DNzic5zL"
   },
   "source": [
    "# Enhancing Performance on CIFAR-10 using ResNet-18 models\n",
    "#### Agata Kopyt\n",
    "\n",
    "### Introduction\n",
    "\n",
    "The objective of the term project is to improve the performance on the CIFAR-10 dataset using the ResNet-18 architecture. The CIFAR-10 dataset consists of 60,000 32x32 colour images across 10 different classes. The goal is to develop a model that classifies these images with the best accuracy. The dataset can be downloaded from the [website](https://www.cs.toronto.edu/~kriz/cifar.html). The baseline code to which improvements were added is available in the [linked repository](https://github.com/heechul-knu/cifar-baseline). My means to create the best deep learning model were limited due to not being in possession of a device with a GPU and the limitations of Google Colab, but nevertheless, I did my best.\n",
    "\n",
    "### Architecture\n",
    "ResNet-18, short for Residual Network-18, is a popular deep convolutional neural network (CNN) architecture that has significantly advanced the field of computer vision. It consists of 18 layers with residual connections, which allow a direct flow of information across layers. Therefore, it effectively mitigates the vanishing gradient problem. Its outstanding performance on various image classification tasks has made ResNet-18 a famous architecture among researchers and practitioners. For the term project, only the ResNet-18 architecture without any modifications was allowed.\n",
    "\n",
    "### Methodology\n",
    "For the methodology, I implemented the data transformation and augmentation practises learned at the Deep Learning course by myself. Additionally, I experimented with the optimizer choice. Later, I researched the best practises for improving CIFAR-10 accuracy, already discovered by the data scientists.\n",
    "\n",
    "#### Optimizer\n",
    "I started making improvements by choosing the optimizer. The baseline code used the famously recommended SGDM optimizer. I decided to compare the performances of the models using the Adam optimizer and the Adamax optimizer.\n",
    "\n",
    "#### Data Augmentation and Transformation\n",
    "The baseline code had already implemented resizing, random cropping, random horizontal flipping, and normalisation. Based on the knowledge from the Deep Learning course, I additionally performed on the training dataset random vertical flip, random rotation, gaussian blur, colour jitter, random affine, and random perspective.\n",
    "\n",
    "In the [PyTorch documentation](https://pytorch.org/vision/stable/transforms.html#auto-augmentation), I discovered Auto-Augmentation functions. Among the offered functions, the `AutoAugment` function was based on the article [\"AutoAugment:\n",
    "Learning Augmentation Strategies from Data\"](https://arxiv.org/pdf/1805.09501.pdf) written by Ekin D. Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan and Quoc V. Le. The procedure introduced in the article was developed using ResNet architecture and the CIFAR-10 dataset (among others) and offers a policy learned on a CIFAR-10 dataset. \n",
    "\n",
    "Inspired by the paper [\"Random Erasing Data Augmentation\"](https://ojs.aaai.org/index.php/AAAI/article/view/7000) written by Zhun Zhong, Liang Zheng, Guoliang Kang, Shaozi Li and Yi Yang, I performed random erasing on the training dataset. The article states that this method improves the robustness of CNNs for partially occluded samples, in particular using the CIFAR-10 dataset and ResNet architectures.\n",
    "\n",
    "####  Improvement of Model Development\n",
    "To improve the baseline models, I experimented with the number of models in the ensemble and the number of epochs for each model. Also, I aspired to implement the method learned in the article called [\"Shake-Shake regularization\"](https://www.cs.toronto.edu/~kriz/cifar.html) by Xavier Gastaldi. The idea introduced in this paper helps solve the overfitting problem. The researcher himself used CIFAR-10 to present the promising performance of the method, giving high hopes for improvement. Unfortunately, before I implemented it in my code, I ran out of computing units on Google Colab and was forced to abandon this idea.\n",
    "\n",
    "#### Performance Evaluation: \n",
    "To evaluate the performance of the models I created, I used accuracy.\n",
    "\n",
    "### Results\n",
    "Firstly, I compared the results of the SGDM, Adam and Adamax optimizers. The Adamax optimizer turned out to provide the best accuracy, and I chose it for developing the final models.\n",
    "\n",
    "Then I experimented with data transformation and augmentation methods. To minimise the time spent compiling the code during constant development of the model, I tested those methods one by one on models created over a small number of epochs (20). Only resizing, random cropping, random horizontal flip, and normalisation improved the accuracy, while the other methods worsened it. Keeping in mind that sometimes transformation or augmentation methods can initially provide noise and worsen the accuracy because of the low number of epochs used for the models, I checked the performance of the models created with the mentioned methods and a higher number of epochs (60). Unfortunately, the accuracy did not improve.\n",
    "\n",
    "Using `AutoAugment` with the CIFAR-10 policy improved the baseline accuracy to **97.17%** (using ensemble of 2 models created using 50 epochs each). The accuracy of five ensemble models (using 60 epochs for each) improved to **97.4%**.\n",
    "\n",
    "Finally, I added random erasing to the training dataset. Ensembling 3 models with 55 epochs for each increased the accuracy to **97.43%**. I tried training and ensembling 5 such models, but the accuracy dropped to **97.38%**. By comparing the accuracies, I found the best combination from the 5 models, which resulted in the best being ensembling the first 3 models.\n",
    "\n",
    "### Conclusion\n",
    "Among SGDM, Adam, and Adamax, Adamax is the best optimizer for the problem introduced in the term project.\n",
    "\n",
    "Testing and combining various transformation and augmentation methods for enhancing the accuracy of the classification model resulted in `AutoAugment` and random erasing being the best, in addition to the methods used in the baseline model. That is a reasonable result, because `AutoAugment` was created especially to be used on the CIFAR-10 dataset by a group of researchers with experience and better resources. Other methods, which failed, could supposedly improve the performance with an even larger number of epochs, but the resources limited those aspirations.\n",
    "\n",
    "Even though ensembling a larger number of models (5) with auto-augmentation improved the accuracy, when random ereasing was added, a smaller number of models (3) turned out to be sufficient and even performed better than ensembling 4 or 5 models.\n",
    "\n",
    "At some point, increasing the number of epochs was not efficient due to small improvements over a long compiling time, but using a better device might provide even better accuracy.\n",
    "\n",
    "Implementing Shake-Shake regularisation could result in better performance, but it would require more computing units.\n",
    "\n",
    "Overall, the result of **97.43%** is a satisfactory improvement given the limited resources."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPHRpuGfFD0JyY9CYC8XxD1",
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
